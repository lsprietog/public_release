{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/lsprietog/public_release/blob/main/demo_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "# \ud83c\udf93 IVIM-DKI Machine Learning Demo\n",
    "\n",
    "This notebook demonstrates how to train and evaluate Machine Learning models for Diffusion MRI analysis, as described in the paper **\"Exploring the Potential of Machine Learning Algorithms to Improve Diffusion Nuclear Magnetic Resonance Imaging Models Analysis\"**.\n",
    "\n",
    "**What you will learn:**\n",
    "1. How to generate synthetic IVIM-DKI signal data.\n",
    "2. How to train Random Forest and Extra Trees models.\n",
    "3. How to compare ML performance against standard Least Squares fitting.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1. Setup & Install\n",
    "!git clone https://github.com/lsprietog/public_release.git\n",
    "%cd public_release\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.optimize import curve_fit\n",
    "import joblib\n",
    "\n",
    "# Define the IVIM-DKI model function\n",
    "def ivim_dki_model(b, D, f, Dstar, K):\n",
    "    return f * np.exp(-b * Dstar) + (1 - f) * np.exp(-b * D + (1/6) * (b**2) * (D**2) * K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 2. Generate Synthetic Data\n",
    "# Simulation parameters\n",
    "n_samples = 5000\n",
    "b_values = np.array([0, 10, 20, 30, 50, 80, 100, 150, 200, 400, 600, 800, 1000, 1500, 2000])\n",
    "snr = 30\n",
    "\n",
    "# Random ground truth parameters\n",
    "np.random.seed(42)\n",
    "D_true = np.random.uniform(0.0005, 0.003, n_samples)\n",
    "f_true = np.random.uniform(0.1, 0.4, n_samples)\n",
    "Dstar_true = np.random.uniform(0.005, 0.1, n_samples)\n",
    "K_true = np.random.uniform(0, 2.0, n_samples)\n",
    "\n",
    "Y_true = np.stack([D_true, f_true, Dstar_true, K_true], axis=1)\n",
    "\n",
    "# Generate signals\n",
    "signals = []\n",
    "for i in range(n_samples):\n",
    "    sig = ivim_dki_model(b_values, D_true[i], f_true[i], Dstar_true[i], K_true[i])\n",
    "    # Add Rician noise\n",
    "    noise_r = np.random.normal(0, 1/snr, len(b_values))\n",
    "    noise_i = np.random.normal(0, 1/snr, len(b_values))\n",
    "    noisy_sig = np.sqrt((sig + noise_r)**2 + noise_i**2)\n",
    "    signals.append(noisy_sig)\n",
    "\n",
    "X = np.array(signals)\n",
    "print(f\"Generated {n_samples} synthetic signals with SNR={snr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 3. Train Machine Learning Model\n",
    "print(\"Training Extra Trees Regressor...\")\n",
    "# Using optimized hyperparameters for speed/size balance\n",
    "model = ExtraTreesRegressor(\n",
    "    n_estimators=50,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X, Y_true)\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# Evaluate\n",
    "Y_pred = model.predict(X)\n",
    "r2 = r2_score(Y_true, Y_pred)\n",
    "print(f\"Model R2 Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 4. Visualize Results\n",
    "param_names = ['D', 'f', 'D*', 'K']\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "for i in range(4):\n",
    "    axes[i].scatter(Y_true[:, i], Y_pred[:, i], alpha=0.1, s=5)\n",
    "    axes[i].plot([Y_true[:, i].min(), Y_true[:, i].max()], \n",
    "                 [Y_true[:, i].min(), Y_true[:, i].max()], 'r--')\n",
    "    axes[i].set_xlabel('Ground Truth')\n",
    "    axes[i].set_ylabel('Prediction')\n",
    "    axes[i].set_title(f'{param_names[i]} (R2={r2_score(Y_true[:, i], Y_pred[:, i]):.2f})')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 5. Save Model\n",
    "joblib.dump(model, 'my_trained_model.joblib')\n",
    "print(\"Model saved as 'my_trained_model.joblib'\")\n",
    "files.download('my_trained_model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}